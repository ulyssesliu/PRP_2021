{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df2 = pd.read_csv('F:/大学/第40期PRP/特征提取/1_feature_analysis/' + 'Intergated-DATASET-C' + '.csv')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from utm import *\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "from osgeo import osr\n",
    "import coordTransform\n",
    "\n",
    "# 预设地址和其他全局变量\n",
    "feature_file_name = 'Intergated-DATASET-D'\n",
    "raw_data_path = 'F:/大学/第40期PRP/交通订单数据/traffic_data/'\n",
    "feature_dst_path = 'F:/大学/第40期PRP/特征提取/1_feature_analysis/' + feature_file_name + '.csv'\n",
    "day_begin = '06:00:00'\n",
    "day_end = '23:00:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_20161101 处理完毕，放入list\n",
      "feature_20161102 处理完毕，放入list\n",
      "feature_20161103 处理完毕，放入list\n",
      "feature_20161104 处理完毕，放入list\n",
      "feature_20161105 处理完毕，放入list\n",
      "feature_20161106 处理完毕，放入list\n",
      "feature_20161107 处理完毕，放入list\n",
      "feature_20161108 处理完毕，放入list\n",
      "feature_20161109 处理完毕，放入list\n",
      "feature_20161110 处理完毕，放入list\n",
      "feature_20161111 处理完毕，放入list\n",
      "feature_20161112 处理完毕，放入list\n",
      "feature_20161113 处理完毕，放入list\n",
      "feature_20161114 处理完毕，放入list\n",
      "feature_20161115 处理完毕，放入list\n",
      "feature_20161116 处理完毕，放入list\n",
      "feature_20161117 处理完毕，放入list\n",
      "feature_20161118 处理完毕，放入list\n",
      "feature_20161119 处理完毕，放入list\n",
      "feature_20161120 处理完毕，放入list\n",
      "feature_20161121 处理完毕，放入list\n",
      "feature_20161122 处理完毕，放入list\n",
      "feature_20161123 处理完毕，放入list\n",
      "feature_20161124 处理完毕，放入list\n",
      "feature_20161125 处理完毕，放入list\n",
      "feature_20161126 处理完毕，放入list\n",
      "feature_20161127 处理完毕，放入list\n",
      "feature_20161128 处理完毕，放入list\n",
      "feature_20161129 处理完毕，放入list\n",
      "feature_20161130 处理完毕，放入list\n",
      "已生成Intergated-DATASET-D\n"
     ]
    }
   ],
   "source": [
    "#在此处设置时间窗(单位为3秒)和空间网格的边长(WGS84坐标系)\n",
    "time_interval = 200\n",
    "space_interval = 70\n",
    "# 滞留时间阈值，超过阈值视为无效订单\n",
    "\n",
    "# 设置时间区间 读取原数据\n",
    "# 时间区间: 减少单次的处理量\n",
    "jar = []\n",
    "\n",
    "for date in range(20161101,20161131):\n",
    "    if not os.path.exists('F:/大学/第40期PRP/特征提取/1_feature_analysis/' + f'feature_{date}.csv'):\n",
    "\n",
    "        time1 = f'{date} {day_begin}'\n",
    "        time2 = f'{date} {day_end}'\n",
    "        stamp1 = time.mktime(time.strptime(time1, '%Y%m%d %H:%M:%S'))\n",
    "        stamp2 = time.mktime(time.strptime(time2, '%Y%m%d %H:%M:%S'))\n",
    "\n",
    "        print(f'正在导入数据：gps_{date}.csv')\n",
    "        #导入原地理数据\n",
    "        df = pd.read_csv(raw_data_path+f'gps_{date}.csv', header = None) #注意我此处使用的是移动硬盘的地址\n",
    "        df.columns = ['driver_ID', 'order_ID', 'timestamp', 'lon', 'lat']\n",
    "        df.timestamp = df.timestamp + 8*3600\n",
    "        print(f'已导入数据：gps_{date}.csv')\n",
    "        ## 只取预设时间区间内的数据\n",
    "        df = df[(df['timestamp'] >= stamp1)&(df['timestamp'] < stamp2)].reset_index(drop = True)\n",
    "\n",
    "        # 将空间坐标转换为WGS-84(耗时会很长)\n",
    "        xy = df[['lon','lat']].apply(lambda x: coordTransform.gcj02_to_wgs84(x[0],x[1])[:2], axis = 1)\n",
    "        df['lon'] = [x[0] for x in xy]\n",
    "        df['lat'] = [x[1] for x in xy]\n",
    "        print (f'{date} 已生成WGS-84')\n",
    "\n",
    "        # 再把WGS-84转换为UTM平面直角系(保留WGS-84数据)\n",
    "        wgs84 = osr.SpatialReference()\n",
    "        wgs84.ImportFromEPSG(4326)\n",
    "        # 2.Pseudo-Mercator\n",
    "        inp = osr.SpatialReference()\n",
    "        inp.ImportFromEPSG(3857)\n",
    "        # 3.定义坐标变换映射\n",
    "        transformation = osr.CoordinateTransformation(wgs84, inp)\n",
    "        # 4.转换原数据的坐标\n",
    "        print(f'{date} 正在转换原数据坐标')\n",
    "        xy = df[['lon','lat']].apply(lambda x: transformation.TransformPoint(x[0],x[1])[:2], axis = 1)\n",
    "        print(f'{date} 已转换原数据坐标')\n",
    "        # 5.写入df\n",
    "        df['x'] = [x[0] for x in xy]\n",
    "        df['y'] = [x[1] for x in xy]\n",
    "        print (f'{date} 已生成UTM, 当前数据条数：',len(df))\n",
    "\n",
    "        # 时间窗划分\n",
    "        df['time_id'] = df.timestamp.apply(lambda x: (x - stamp1)//time_interval)\n",
    "\n",
    "        # 空间网格划分\n",
    "        # 1.计算左边界和上边界，左右-x， 上下-y\n",
    "        left = df['x'].min()\n",
    "        down = df['y'].max()\n",
    "\n",
    "        # 2.生成横向和纵向索引\n",
    "        df['row_id'] = df['y'].apply(lambda y: (y - down)//space_interval)\n",
    "        df['col_id'] = df['x'].apply(lambda x: (x - left)//space_interval)\n",
    "\n",
    "        print (f'{date} 已生成时空索引')\n",
    "\n",
    "        df = df.dropna()\n",
    "        print (f'{date} 已处理空值, 当前数据条数：',len(df))\n",
    "\n",
    "        # 下面开始时空特征提取\n",
    "\n",
    "        #1. 计算瞬时速度\n",
    "        # 排序：先按司机排，同司机按订单排，同订单再按时间排\n",
    "        print(f'{date} 正在计算瞬时速度')\n",
    "        df = df.sort_values(by = ['driver_ID', 'order_ID', 'timestamp']).reset_index(drop = True)\n",
    "        # 将订单id下移一行，用于判断前后数据是否属于同一订单\n",
    "        df['orderFlag'] = df['order_ID'].shift(1)\n",
    "        df['identi'] = (df['orderFlag'] == df['order_ID']) #一个由boolean构成的列，方便后面所有shift完成了之后再删除分界行\n",
    "        # 将坐标，时间戳下移一行，匹配相应轨迹点\n",
    "        df['x1'] = df['x'].shift(1)\n",
    "        df['y1'] = df['y'].shift(1)\n",
    "        df['timestamp1'] = df['timestamp'].shift(1)\n",
    "        # 将不属于同一订单的轨迹点删除\n",
    "        df = df[df['identi'] == True]\n",
    "        # 计算相邻轨迹点之间的距离和相差时间\n",
    "        # 距离采用欧式距离\n",
    "        dist = np.sqrt(np.square(df['x'].values - df['x1'].values) + np.square(df['y'].values - df['y1'].values))\n",
    "        ttime = df['timestamp'].values - df['timestamp1'].values\n",
    "        # 计算速度\n",
    "        df['speed'] = dist/ttime\n",
    "        # 删除临时数据\n",
    "        df = df.drop(columns = ['x1', 'y1', 'orderFlag', 'timestamp1', 'identi'])\n",
    "        print(f'{date} 已生成速度')\n",
    "\n",
    "        # 2.计算瞬时加速度\n",
    "        print(f'{date} 正在计算加速度')\n",
    "        df['speed1'] = df['speed'].shift(1)\n",
    "        df['timestamp1'] = df['timestamp'].shift(1)\n",
    "        df['identi'] = df['order_ID'].shift(1)\n",
    "        df = df[df.identi == df.order_ID]\n",
    "        df['acc'] = (df.speed - df.speed1)/(df.timestamp - df.timestamp1)\n",
    "        df = df.drop(columns = ['speed1', 'timestamp1', 'identi'])\n",
    "        print(f'{date} 已生成加速度')\n",
    "\n",
    "        df = df.reset_index(drop = True)\n",
    "\n",
    "        # 下面计算集体/网格平均特征\n",
    "\n",
    "        # 1. 网格平均速度：先求每辆车在网格中的平均速度，然后求网格中所有个体平均速度的军制\n",
    "        # 基于时空网格和估计id分组\n",
    "        print(f'{date} 正在生成平均网格速度')\n",
    "        orderGrouped = df.groupby(['row_id', 'col_id', 'time_id', 'order_ID'])\n",
    "        # 网格在每个时刻（时间窗）的平均速度\n",
    "        grouped_speed = orderGrouped.speed.mean().reset_index()\n",
    "        grouped_speed = grouped_speed.groupby(['row_id', 'col_id', 'time_id'])\n",
    "        grid_speed = grouped_speed.speed.mean()\n",
    "        # 去除异常值\n",
    "        grid_speed = grid_speed.clip(grid_speed.quantile(0.05), grid_speed.quantile(0.95))\n",
    "        print(f'{date} 已生成网格平均速度')\n",
    "\n",
    "        # 2. 网格平均加速度\n",
    "        print(f'{date} 正在生成网格平均加速度')\n",
    "        gridGrouped = df.groupby(['row_id', 'col_id', 'time_id'])\n",
    "        grid_acc = gridGrouped.acc.mean()\n",
    "        print(f'{date} 已生成网格平均加速度')\n",
    "\n",
    "        # 3.网格浮动车流量\n",
    "        print(f'{date} 正在生成网格浮动车数量')\n",
    "        grouped_volume = orderGrouped.speed.last().reset_index() #每个时空网格中的每个order只保留一辆（用last（）来取）\n",
    "        grouped_volume = grouped_volume.groupby(['row_id', 'col_id', 'time_id'])\n",
    "        grid_volume = grouped_volume['speed'].size()\n",
    "        grid_volume = grid_volume.clip(grid_volume.quantile(0.05), grid_volume.quantile(0.95))\n",
    "        print(f'{date} 已生成网格浮动车数量')\n",
    "\n",
    "        # 4.网格车速标准差\n",
    "        print(f'{date} 正在生成网格车速标准差')\n",
    "        grid_v_std = gridGrouped.speed.std(ddof=0)\n",
    "        # 去除异常值\n",
    "        grid_v_std = grid_v_std.clip(grid_v_std.quantile(0.05), grid_v_std.quantile(0.95))\n",
    "        print(f'{date} 已生成网格车速标准差')\n",
    "\n",
    "        # 5.网格平均停车次数\n",
    "        print(f'{date} 正在生成网格平均停车次数')\n",
    "        stopNum = gridGrouped.speed.agg(lambda x: (x==0).sum())\n",
    "        grid_stop = pd.concat((stopNum, grid_volume), axis = 1)\n",
    "        grid_stop['stopNum'] = stopNum.values/ grid_volume.values\n",
    "        grid_stop = grid_stop['stopNum']\n",
    "        grid_stop = grid_stop.clip(0, grid_stop.quantile(0.95))\n",
    "        print(f'{date} 已生成网格平均停车次数')\n",
    "\n",
    "        feature = pd.concat([grid_speed, grid_acc, grid_volume, grid_v_std, grid_stop], axis = 1).reset_index()\n",
    "        feature.columns = ['row_id','col_id', 'time_id', 'aveSpeed', 'gridAcc', 'volume', 'speedStd', 'stopNum']\n",
    "        print(f'{date} 已整理网格特征')\n",
    "        feature.sort_values(['stopNum']).reset_index(drop=True)\n",
    "        feature['date'] = date\n",
    "\n",
    "        jar.append(feature)\n",
    "        feature.to_csv('F:/大学/第40期PRP/特征提取/1_feature_analysis/' + f'feature_{date}.csv')\n",
    "        print(f'{date} 处理完毕，放入list')\n",
    "    \n",
    "    else:\n",
    "        feature = pd.read_csv('F:/大学/第40期PRP/特征提取/1_feature_analysis/' + f'feature_{date}.csv')\n",
    "        jar.append(feature)\n",
    "        print(f'feature_{date} 处理完毕，放入list')\n",
    "\n",
    "integrated_feature = pd.concat(jar, axis=0)\n",
    "integrated_feature.to_csv(feature_dst_path, index = None)\n",
    "print(f'已生成{feature_file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>col_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>aveSpeed</th>\n",
       "      <th>gridAcc</th>\n",
       "      <th>volume</th>\n",
       "      <th>speedStd</th>\n",
       "      <th>stopNum</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-139.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.571961</td>\n",
       "      <td>-2.323410</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-139.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.679653</td>\n",
       "      <td>-0.098228</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-139.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.348424</td>\n",
       "      <td>0.018499</td>\n",
       "      <td>2</td>\n",
       "      <td>1.345171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-139.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>9.483641</td>\n",
       "      <td>0.109564</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-139.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.754410</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119540</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>11.870780</td>\n",
       "      <td>-0.933510</td>\n",
       "      <td>2</td>\n",
       "      <td>1.940621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119541</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>18.987620</td>\n",
       "      <td>-3.600893</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119542</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>12.517520</td>\n",
       "      <td>-1.124392</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119543</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>15.536704</td>\n",
       "      <td>-0.322319</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119544</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>17.262123</td>\n",
       "      <td>-0.434894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20161130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32887998 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         row_id  col_id  time_id   aveSpeed   gridAcc  volume  speedStd  \\\n",
       "0        -139.0     5.0     45.0  15.571961 -2.323410       1  0.000000   \n",
       "1        -139.0     5.0     48.0  10.679653 -0.098228       1  0.000000   \n",
       "2        -139.0     5.0     51.0  12.348424  0.018499       2  1.345171   \n",
       "3        -139.0     5.0     54.0   9.483641  0.109564       1  0.000000   \n",
       "4        -139.0     5.0     60.0  12.754410 -0.000014       1  0.000000   \n",
       "...         ...     ...      ...        ...       ...     ...       ...   \n",
       "1119540    -1.0    52.0    299.0  11.870780 -0.933510       2  1.940621   \n",
       "1119541    -1.0    52.0    300.0  18.987620 -3.600893       1  0.000000   \n",
       "1119542    -1.0    52.0    301.0  12.517520 -1.124392       1  0.000000   \n",
       "1119543    -1.0    52.0    302.0  15.536704 -0.322319       1  0.000000   \n",
       "1119544    -1.0    52.0    304.0  17.262123 -0.434894       1  0.000000   \n",
       "\n",
       "         stopNum      date  \n",
       "0            0.0  20161101  \n",
       "1            0.0  20161101  \n",
       "2            0.0  20161101  \n",
       "3            0.0  20161101  \n",
       "4            0.0  20161101  \n",
       "...          ...       ...  \n",
       "1119540      0.0  20161130  \n",
       "1119541      0.0  20161130  \n",
       "1119542      0.0  20161130  \n",
       "1119543      0.0  20161130  \n",
       "1119544      0.0  20161130  \n",
       "\n",
       "[32887998 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrated_feature.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_feature.to_csv(feature_dst_path, index = None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
